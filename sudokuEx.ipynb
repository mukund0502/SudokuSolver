{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded saved model from disk.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import operator\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# from NumberExtractor import extract_number\n",
    "\n",
    "\n",
    "def plot_many_images(images, titles, rows=1, columns=2):\n",
    "\t\"\"\"Plots each image in a given list as a grid structure. using Matplotlib.\"\"\"\n",
    "\tfor i, image in enumerate(images):\n",
    "\t\tplt.subplot(rows, columns, i+1)\n",
    "\t\tplt.imshow(image, 'gray')\n",
    "\t\tplt.title(titles[i])\n",
    "\t\tplt.xticks([]), plt.yticks([])  # Hide tick marks\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "def show_image(img):\n",
    "    \"\"\"Shows an image until any key is pressed\"\"\"\n",
    "#    print(type(img))\n",
    "#    print(img.shape)\n",
    "#    cv2.imshow('image', img)  # Display the image\n",
    "#    cv2.imwrite('images/gau_sudoku3.jpg', img)\n",
    "#    cv2.waitKey(0)  # Wait for any key to be pressed (with the image window active)\n",
    "#    cv2.destroyAllWindows()  # Close all windows\n",
    "    return img\n",
    "\n",
    "\n",
    "def show_digits(digits, colour=255):\n",
    "    \"\"\"Shows list of 81 extracted digits in a grid format\"\"\"\n",
    "    rows = []\n",
    "    with_border = [cv2.copyMakeBorder(img.copy(), 1, 1, 1, 1, cv2.BORDER_CONSTANT, None, colour) for img in digits]\n",
    "    for i in range(9):\n",
    "        row = np.concatenate(with_border[i * 9:((i + 1) * 9)], axis=1)\n",
    "        rows.append(row)\n",
    "    img = show_image(np.concatenate(rows))\n",
    "    return img\n",
    " \n",
    "\n",
    "def convert_when_colour(colour, img):\n",
    "\t\"\"\"Dynamically converts an image to colour if the input colour is a tuple and the image is grayscale.\"\"\"\n",
    "\tif len(colour) == 3:\n",
    "\t\tif len(img.shape) == 2:\n",
    "\t\t\timg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\t\telif img.shape[2] == 1:\n",
    "\t\t\timg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\treturn img\n",
    "\n",
    "\n",
    "def display_points(in_img, points, radius=5, colour=(0, 0, 255)):\n",
    "\t\"\"\"Draws circular points on an image.\"\"\"\n",
    "\timg = in_img.copy()\n",
    "\n",
    "\t# Dynamically change to a colour image if necessary\n",
    "\tif len(colour) == 3:\n",
    "\t\tif len(img.shape) == 2:\n",
    "\t\t\timg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\t\telif img.shape[2] == 1:\n",
    "\t\t\timg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "\tfor point in points:\n",
    "\t\timg = cv2.circle(img, tuple(int(x) for x in point), radius, colour, -1)\n",
    "\tshow_image(img)\n",
    "\treturn img\n",
    "\n",
    "\n",
    "def display_rects(in_img, rects, colour=(0, 0, 255)):\n",
    "\t\"\"\"Displays rectangles on the image.\"\"\"\n",
    "\timg = convert_when_colour(colour, in_img.copy())\n",
    "\tfor rect in rects:\n",
    "\t\timg = cv2.rectangle(img, tuple(int(x) for x in rect[0]), tuple(int(x) for x in rect[1]), colour)\n",
    "\tshow_image(img)\n",
    "\treturn img\n",
    "\n",
    "\n",
    "def display_contours(in_img, contours, colour=(0, 0, 255), thickness=2):\n",
    "\t\"\"\"Displays contours on the image.\"\"\"\n",
    "\timg = convert_when_colour(colour, in_img.copy())\n",
    "\timg = cv2.drawContours(img, contours, -1, colour, thickness)\n",
    "\tshow_image(img)\n",
    "\n",
    "\n",
    "def pre_process_image(img, skip_dilate=False):\n",
    "\t\"\"\"Uses a blurring function, adaptive thresholding and dilation to expose the main features of an image.\"\"\"\n",
    "\n",
    "\t# Gaussian blur with a kernal size (height, width) of 9.\n",
    "\t# Note that kernal sizes must be positive and odd and the kernel must be square.\n",
    "\t\n",
    "\timg2 = img.copy()\n",
    "\tproc = cv2.GaussianBlur(img2, (9, 9), 0)\n",
    "\n",
    "\t# Adaptive threshold using 11 nearest neighbour pixels\n",
    "\tproc = cv2.adaptiveThreshold(proc, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "\t# Invert colours, so gridlines have non-zero pixel values.\n",
    "\t# Necessary to dilate the image, otherwise will look like erosion instead.\n",
    "\tproc = cv2.bitwise_not(proc, proc)\n",
    "\n",
    "\tif not skip_dilate:\n",
    "\t\t# Dilate the image to increase the size of the grid lines.\n",
    "\t\tkernel = np.array([[0., 1., 0.], [1., 1., 1.], [0., 1., 0.]],np.uint8)\n",
    "\t\tproc = cv2.dilate(proc, kernel)\n",
    "\n",
    "\treturn proc\n",
    "\n",
    "\n",
    "def find_corners_of_largest_polygon(img):\n",
    "\t\"\"\"Finds the 4 extreme corners of the largest contour in the image.\"\"\"\n",
    "\topencv_version = cv2.__version__.split('.')[0]\n",
    "\tif opencv_version == '3':\n",
    "\t\t_, contours, h = cv2.findContours(img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # Find contours\n",
    "\telse:\n",
    "\t\tcontours, h = cv2.findContours(img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # Find contours\n",
    "\tcontours = sorted(contours, key=cv2.contourArea, reverse=True)  # Sort by area, descending\n",
    "\tpolygon = contours[0]  # Largest image\n",
    "\n",
    "\t# Use of `operator.itemgetter` with `max` and `min` allows us to get the index of the point\n",
    "\t# Each point is an array of 1 coordinate, hence the [0] getter, then [0] or [1] used to get x and y respectively.\n",
    "\n",
    "\t# Bottom-right point has the largest (x + y) value\n",
    "\t# Top-left has point smallest (x + y) value\n",
    "\t# Bottom-left point has smallest (x - y) value\n",
    "\t# Top-right point has largest (x - y) value\n",
    "\tbottom_right, _ = max(enumerate([pt[0][0] + pt[0][1] for pt in polygon]), key=operator.itemgetter(1))\n",
    "\ttop_left, _ = min(enumerate([pt[0][0] + pt[0][1] for pt in polygon]), key=operator.itemgetter(1))\n",
    "\tbottom_left, _ = min(enumerate([pt[0][0] - pt[0][1] for pt in polygon]), key=operator.itemgetter(1))\n",
    "\ttop_right, _ = max(enumerate([pt[0][0] - pt[0][1] for pt in polygon]), key=operator.itemgetter(1))\n",
    "\n",
    "\t# Return an array of all 4 points using the indices\n",
    "\t# Each point is in its own array of one coordinate\n",
    "\treturn [polygon[top_left][0], polygon[top_right][0], polygon[bottom_right][0], polygon[bottom_left][0]]\n",
    "\n",
    "\n",
    "def distance_between(p1, p2):\n",
    "\t\"\"\"Returns the scalar distance between two points\"\"\"\n",
    "\ta = p2[0] - p1[0]\n",
    "\tb = p2[1] - p1[1]\n",
    "\treturn np.sqrt((a ** 2) + (b ** 2))\n",
    "\n",
    "\n",
    "def crop_and_warp(img, crop_rect):\n",
    "\t\"\"\"Crops and warps a rectangular section from an image into a square of similar size.\"\"\"\n",
    "\n",
    "\t# Rectangle described by top left, top right, bottom right and bottom left points\n",
    "\ttop_left, top_right, bottom_right, bottom_left = crop_rect[0], crop_rect[1], crop_rect[2], crop_rect[3]\n",
    "\n",
    "\t# Explicitly set the data type to float32 or `getPerspectiveTransform` will throw an error\n",
    "\tsrc = np.array([top_left, top_right, bottom_right, bottom_left], dtype='float32')\n",
    "\n",
    "\t# Get the longest side in the rectangle\n",
    "\tside = max([\n",
    "\t\tdistance_between(bottom_right, top_right),\n",
    "\t\tdistance_between(top_left, bottom_left),\n",
    "\t\tdistance_between(bottom_right, bottom_left),\n",
    "\t\tdistance_between(top_left, top_right)\n",
    "\t])\n",
    "\n",
    "\t# Describe a square with side of the calculated length, this is the new perspective we want to warp to\n",
    "\tdst = np.array([[0, 0], [side - 1, 0], [side - 1, side - 1], [0, side - 1]], dtype='float32')\n",
    "\n",
    "\t# Gets the transformation matrix for skewing the image to fit a square by comparing the 4 before and after points\n",
    "\tm = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "\t# Performs the transformation on the original image\n",
    "\treturn cv2.warpPerspective(img, m, (int(side), int(side)))\n",
    "\n",
    "\n",
    "def infer_grid(img):\n",
    "\t\"\"\"Infers 81 cell grid from a square image.\"\"\"\n",
    "\tsquares = []\n",
    "\tside = img.shape[:1]\n",
    "\tside = side[0] / 9\n",
    "\n",
    "\t# Note that we swap j and i here so the rectangles are stored in the list reading left-right instead of top-down.\n",
    "\tfor j in range(9):\n",
    "\t\tfor i in range(9):\n",
    "\t\t\tp1 = (i * side, j * side)  # Top left corner of a bounding box\n",
    "\t\t\tp2 = ((i + 1) * side, (j + 1) * side)  # Bottom right corner of bounding box\n",
    "\t\t\tsquares.append((p1, p2))\n",
    "\treturn squares\n",
    "\n",
    "\n",
    "def cut_from_rect(img, rect):\n",
    "\t\"\"\"Cuts a rectangle from an image using the top left and bottom right points.\"\"\"\n",
    "\treturn img[int(rect[0][1]):int(rect[1][1]), int(rect[0][0]):int(rect[1][0])]\n",
    "\n",
    "\n",
    "def scale_and_centre(img, size, margin=0, background=0):\n",
    "\t\"\"\"Scales and centres an image onto a new background square.\"\"\"\n",
    "\th, w = img.shape[:2]\n",
    "\n",
    "\tdef centre_pad(length):\n",
    "\t\t\"\"\"Handles centering for a given length that may be odd or even.\"\"\"\n",
    "\t\tif length % 2 == 0:\n",
    "\t\t\tside1 = int((size - length) / 2)\n",
    "\t\t\tside2 = side1\n",
    "\t\telse:\n",
    "\t\t\tside1 = int((size - length) / 2)\n",
    "\t\t\tside2 = side1 + 1\n",
    "\t\treturn side1, side2\n",
    "\n",
    "\tdef scale(r, x):\n",
    "\t\treturn int(r * x)\n",
    "\n",
    "\tif h > w:\n",
    "\t\tt_pad = int(margin / 2)\n",
    "\t\tb_pad = t_pad\n",
    "\t\tratio = (size - margin) / h\n",
    "\t\tw, h = scale(ratio, w), scale(ratio, h)\n",
    "\t\tl_pad, r_pad = centre_pad(w)\n",
    "\telse:\n",
    "\t\tl_pad = int(margin / 2)\n",
    "\t\tr_pad = l_pad\n",
    "\t\tratio = (size - margin) / w\n",
    "\t\tw, h = scale(ratio, w), scale(ratio, h)\n",
    "\t\tt_pad, b_pad = centre_pad(h)\n",
    "\n",
    "\timg = cv2.resize(img, (w, h))\n",
    "\timg = cv2.copyMakeBorder(img, t_pad, b_pad, l_pad, r_pad, cv2.BORDER_CONSTANT, None, background)\n",
    "\treturn cv2.resize(img, (size, size))\n",
    "\n",
    "\n",
    "def find_largest_feature(inp_img, scan_tl=None, scan_br=None):\n",
    "\t\"\"\"\n",
    "\tUses the fact the `floodFill` function returns a bounding box of the area it filled to find the biggest\n",
    "\tconnected pixel structure in the image. Fills this structure in white, reducing the rest to black.\n",
    "\t\"\"\"\n",
    "\timg = inp_img.copy()  # Copy the image, leaving the original untouched\n",
    "\theight, width = img.shape[:2]\n",
    "\n",
    "\tmax_area = 0\n",
    "\tseed_point = (None, None)\n",
    "\n",
    "\tif scan_tl is None:\n",
    "\t\tscan_tl = [0, 0]\n",
    "\n",
    "\tif scan_br is None:\n",
    "\t\tscan_br = [width, height]\n",
    "\n",
    "\t# Loop through the image\n",
    "\tfor x in range(scan_tl[0], scan_br[0]):\n",
    "\t\tfor y in range(scan_tl[1], scan_br[1]):\n",
    "\t\t\t# Only operate on light or white squares\n",
    "\t\t\tif img.item(y, x) == 255 and x < width and y < height:  # Note that .item() appears to take input as y, x\n",
    "\t\t\t\tarea = cv2.floodFill(img, None, (x, y), 64)\n",
    "\t\t\t\tif area[0] > max_area:  # Gets the maximum bound area which should be the grid\n",
    "\t\t\t\t\tmax_area = area[0]\n",
    "\t\t\t\t\tseed_point = (x, y)\n",
    "\n",
    "\t# Colour everything grey (compensates for features outside of our middle scanning range\n",
    "\tfor x in range(width):\n",
    "\t\tfor y in range(height):\n",
    "\t\t\tif img.item(y, x) == 255 and x < width and y < height:\n",
    "\t\t\t\tcv2.floodFill(img, None, (x, y), 64)\n",
    "\n",
    "\tmask = np.zeros((height + 2, width + 2), np.uint8)  # Mask that is 2 pixels bigger than the image\n",
    "\n",
    "\t# Highlight the main feature\n",
    "\tif all([p is not None for p in seed_point]):\n",
    "\t\tcv2.floodFill(img, mask, seed_point, 255)\n",
    "\n",
    "\ttop, bottom, left, right = height, 0, width, 0\n",
    "\n",
    "\tfor x in range(width):\n",
    "\t\tfor y in range(height):\n",
    "\t\t\tif img.item(y, x) == 64:  # Hide anything that isn't the main feature\n",
    "\t\t\t\tcv2.floodFill(img, mask, (x, y), 0)\n",
    "\n",
    "\t\t\t# Find the bounding parameters\n",
    "\t\t\tif img.item(y, x) == 255:\n",
    "\t\t\t\ttop = y if y < top else top\n",
    "\t\t\t\tbottom = y if y > bottom else bottom\n",
    "\t\t\t\tleft = x if x < left else left\n",
    "\t\t\t\tright = x if x > right else right\n",
    "\n",
    "\tbbox = [[left, top], [right, bottom]]\n",
    "\treturn img, np.array(bbox, dtype='float32'), seed_point\n",
    "\n",
    "\n",
    "def extract_digit(img, rect, size):\n",
    "\t\"\"\"Extracts a digit (if one exists) from a Sudoku square.\"\"\"\n",
    "\n",
    "\tdigit = cut_from_rect(img, rect)  # Get the digit box from the whole square\n",
    "\n",
    "\t# Use fill feature finding to get the largest feature in middle of the box\n",
    "\t# Margin used to define an area in the middle we would expect to find a pixel belonging to the digit\n",
    "\th, w = digit.shape[:2]\n",
    "\tmargin = int(np.mean([h, w]) / 2.5)\n",
    "\t_, bbox, seed = find_largest_feature(digit, [margin, margin], [w - margin, h - margin])\n",
    "\tdigit = cut_from_rect(digit, bbox)\n",
    "\n",
    "\t# Scale and pad the digit so that it fits a square of the digit size we're using for machine learning\n",
    "\tw = bbox[1][0] - bbox[0][0]\n",
    "\th = bbox[1][1] - bbox[0][1]\n",
    "\n",
    "\t# Ignore any small bounding boxes\n",
    "\tif w > 0 and h > 0 and (w * h) > 100 and len(digit) > 0:\n",
    "\t\treturn scale_and_centre(digit, size, 4)\n",
    "\telse:\n",
    "\t\treturn np.zeros((size, size), np.uint8)\n",
    "\n",
    "\n",
    "def get_digits(img, squares, size):\n",
    "    \"\"\"Extracts digits from their cells and builds an array\"\"\"\n",
    "    digits = []\n",
    "    img = pre_process_image(img.copy(), skip_dilate=True)\n",
    "#    cv2.imshow('img', img)\n",
    "    for square in squares:\n",
    "        digits.append(extract_digit(img, square, size))\n",
    "    return digits\n",
    "\n",
    "\n",
    "def parse_grid(path):\n",
    "    original = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    processed = pre_process_image(original)\n",
    "    \n",
    "#    cv2.namedWindow('processed',cv2.WINDOW_AUTOSIZE)\n",
    "#    processed_img = cv2.resize(processed, (500, 500))          # Resize image\n",
    "#    cv2.imshow('processed', processed_img)\n",
    "    \n",
    "    corners = find_corners_of_largest_polygon(processed)\n",
    "    cropped = crop_and_warp(original, corners)\n",
    "    \n",
    "#    cv2.namedWindow('cropped',cv2.WINDOW_AUTOSIZE)\n",
    "#    cropped_img = cv2.resize(cropped, (500, 500))              # Resize image\n",
    "#    cv2.imshow('cropped', cropped_img)\n",
    "    \n",
    "    squares = infer_grid(cropped)\n",
    "#    print(squares)\n",
    "    digits = get_digits(cropped, squares, 28)\n",
    "#    print(digits)\n",
    "    final_image = show_digits(digits)\n",
    "    return final_image\n",
    "\n",
    "def extract_sudoku(image_path):\n",
    "    final_image = parse_grid(image_path)\n",
    "    return final_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_sudoku = extract_sudoku(\"sudoku.png\")\n",
    "cv2.imshow(\"image\", extracted_sudoku )\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 270)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_sudoku.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"image\", extracted_sudoku[30:60, :30] )\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (9):\n",
    "    for j in range(9):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91d4e2271cf209bade5eacc82405e130e48ddbdbe9e6210b60ee5c51482ed339"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
